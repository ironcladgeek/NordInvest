"""NordInvest CLI interface."""

import json
import sys
import time
from datetime import date, datetime
from pathlib import Path

import typer

from src.analysis import InvestmentSignal
from src.analysis.signal_creator import SignalCreator
from src.cache.manager import CacheManager
from src.config import load_config
from src.data.db import init_db
from src.data.portfolio import PortfolioState
from src.llm.integration import LLMAnalysisOrchestrator
from src.llm.token_tracker import TokenTracker
from src.MARKET_TICKERS import (
    get_tickers_for_analysis,
    get_tickers_for_markets,
    get_us_categories,
)
from src.pipeline import AnalysisPipeline
from src.utils.llm_check import get_fallback_warning_message, log_llm_status
from src.utils.logging import get_logger, setup_logging
from src.utils.scheduler import RunLog

app = typer.Typer(
    name="nordinvest",
    help="AI-powered financial analysis and investment recommendation system",
    no_args_is_help=True,
)

logger = get_logger(__name__)


def _scan_market_for_anomalies(
    tickers: list[str],
    pipeline: "AnalysisPipeline",
    typer_instance,
    force_full_analysis: bool = False,
    historical_date=None,
) -> list[str]:
    """Scan market for anomalies using rule-based market scanner.

    This is Stage 1 of two-stage LLM analysis - quickly identifies
    instruments with anomalies before expensive LLM analysis.

    Args:
        tickers: List of tickers to scan
        pipeline: Analysis pipeline with market scanner
        typer_instance: Typer instance for output
        force_full_analysis: If True, analyze all tickers when no anomalies found
        historical_date: Optional date for historical analysis

    Returns:
        List of flagged tickers with anomalies

    Raises:
        RuntimeError: If market scan fails (to avoid expensive LLM fallback)
        RuntimeError: If no anomalies found and force_full_analysis=False
    """
    try:
        typer_instance.echo("üîç Stage 1: Scanning market for anomalies...")
        context = {"tickers": tickers}
        if historical_date:
            context["analysis_date"] = historical_date

        # Run market scan
        scan_result = pipeline.crew.market_scanner.execute("Scan market for anomalies", context)

        if scan_result.get("status") != "success":
            error_msg = scan_result.get("message", "Unknown error")
            logger.error(f"Market scan failed: {error_msg}")
            raise RuntimeError(
                f"Market scan failed: {error_msg}\n"
                "Unable to proceed with LLM analysis to avoid incurring unnecessary costs.\n"
                "Please check market data availability and try again."
            )

        # Extract flagged instruments
        flagged = scan_result.get("instruments", [])
        flagged_tickers = [
            instrument.get("ticker") for instrument in flagged if instrument.get("ticker")
        ]

        if not flagged_tickers:
            logger.warning("Market scan completed but found no anomalies")
            if not force_full_analysis:
                raise RuntimeError(
                    "Market scan found no anomalies in the selected instruments.\n"
                    "To analyze all instruments anyway in LLM mode (higher cost), "
                    "use --force-full-analysis flag.\n"
                    "Example: analyze --group us_mega_cap --llm --force-full-analysis"
                )
            typer_instance.echo("  ‚ö†Ô∏è  No anomalies detected, but proceeding with all instruments")
            typer_instance.echo("     (--force-full-analysis flag was provided)")
            return tickers

        typer_instance.echo(
            f"  ‚úì Scan complete: {len(flagged_tickers)} anomalies found "
            f"({len(flagged_tickers)}/{len(tickers)} instruments)"
        )

        return flagged_tickers

    except RuntimeError:
        raise
    except Exception as e:
        logger.error(f"Error in market scan: {e}", exc_info=True)
        raise RuntimeError(
            f"Market scan error: {str(e)}\n"
            "Unable to proceed with LLM analysis to avoid incurring unnecessary costs.\n"
            "Check logs for details."
        )


def _run_llm_analysis(
    tickers: list[str],
    config_obj,
    typer_instance,
    debug_llm: bool = False,
    is_filtered: bool = False,
    cache_manager=None,
    provider_manager=None,
    historical_date=None,
    run_session_id: int | None = None,
    recommendations_repo=None,
) -> tuple[list[InvestmentSignal], None]:
    """Run analysis using LLM-powered orchestrator.

    Args:
        tickers: List of tickers to analyze (pre-filtered if is_filtered=True)
        config_obj: Loaded configuration object
        typer_instance: Typer instance for output
        debug_llm: Enable LLM debug mode (save inputs/outputs)
        is_filtered: Whether tickers have been pre-filtered by market scan
        cache_manager: Cache manager instance
        historical_date: Optional date for historical analysis
        run_session_id: Optional UUID linking signals to analysis run session
        recommendations_repo: Optional repository for storing recommendations

    Returns:
        Tuple of (signals, portfolio_manager)
    """
    try:
        # Initialize LLM orchestrator with token tracking
        data_dir = Path("data")
        tracker = TokenTracker(
            config_obj.token_tracker,
            storage_dir=data_dir / "tracking",
        )

        # Setup debug directory if requested
        debug_dir = None
        if debug_llm:
            debug_dir = data_dir / "llm_debug" / datetime.now().strftime("%Y%m%d_%H%M%S")
            debug_dir.mkdir(parents=True, exist_ok=True)
            typer_instance.echo("  LLM debug mode: enabled")
            typer_instance.echo(f"  Debug outputs: {debug_dir}")

        # Create progress callback for synthesis stage
        def progress_callback(message: str):
            """Display progress messages."""
            typer_instance.echo(message)

        orchestrator = LLMAnalysisOrchestrator(
            llm_config=config_obj.llm,
            token_tracker=tracker,
            enable_fallback=config_obj.llm.enable_fallback,
            debug_dir=debug_dir,
            progress_callback=progress_callback,
            db_path=config_obj.database.db_path if config_obj.database.enabled else None,
            config=config_obj,
        )

        # Set historical date on all tools if provided
        if historical_date:
            typer_instance.echo(f"  Setting historical date {historical_date} on analysis tools...")
            # Access the tool adapter's tool instances
            if hasattr(orchestrator, "tool_adapter"):
                if hasattr(orchestrator.tool_adapter, "price_fetcher"):
                    orchestrator.tool_adapter.price_fetcher.set_historical_date(historical_date)
                if hasattr(orchestrator.tool_adapter, "fundamental_fetcher"):
                    orchestrator.tool_adapter.fundamental_fetcher.set_historical_date(
                        historical_date
                    )
                if hasattr(orchestrator.tool_adapter, "news_fetcher"):
                    orchestrator.tool_adapter.news_fetcher.set_historical_date(historical_date)

        typer_instance.echo(f"  LLM Provider: {config_obj.llm.provider}")
        typer_instance.echo(f"  Model: {config_obj.llm.model}")
        typer_instance.echo(f"  Temperature: {config_obj.llm.temperature}")
        typer_instance.echo("  Token tracking: enabled")

        # Analyze each ticker with LLM
        signals = []
        stage_label = "Stage 2: Deep LLM analysis" if is_filtered else "Analyzing instruments"
        with typer_instance.progressbar(
            tickers, label=stage_label, show_pos=True, show_percent=True
        ) as progress:
            for ticker in progress:
                try:
                    # Create a sub-progress callback for agent tasks
                    task_names = [
                        "market_scan",
                        "technical_analysis",
                        "fundamental_analysis",
                        "sentiment_analysis",
                    ]
                    current_task = [0]  # Use list to allow mutation in nested function

                    def agent_progress_callback(current, total, task_name):
                        """Update progress display for agent tasks."""
                        if current > current_task[0]:
                            current_task[0] = current
                            # Show which agent is working
                            agent_name = task_name.replace("_", " ").title()
                            typer_instance.echo(f"  ‚Üí {agent_name} ({current}/{total})", nl=False)
                            typer_instance.echo("\r", nl=False)  # Carriage return to overwrite

                    # Analyze instrument - returns UnifiedAnalysisResult or None
                    unified_result = orchestrator.analyze_instrument(
                        ticker, progress_callback=agent_progress_callback
                    )

                    # Create signal from unified result using SignalCreator
                    if unified_result:
                        # Initialize SignalCreator with required dependencies
                        signal_creator = SignalCreator(
                            cache_manager=cache_manager,
                            provider_manager=provider_manager,
                            risk_assessor=None,  # Risk assessment already in unified_result
                        )

                        # Create signal from unified analysis result
                        signal = signal_creator.create_signal(
                            result=unified_result,
                            portfolio_context={},
                            analysis_date=historical_date,
                        )

                        if signal:
                            signals.append(signal)

                            # Store signal to database if enabled
                            if recommendations_repo and run_session_id:
                                try:
                                    recommendations_repo.store_recommendation(
                                        signal=signal,
                                        run_session_id=run_session_id,
                                        analysis_mode="llm",
                                        llm_model=config_obj.llm.model,
                                    )
                                except Exception as e:
                                    logger.warning(
                                        f"Failed to store recommendation for {ticker} to database: {e}"
                                    )
                                    # Continue execution - DB failures don't halt pipeline
                    else:
                        logger.warning(f"Analysis failed for {ticker}, skipping")

                except Exception as e:
                    logger.error(f"Error analyzing {ticker} with LLM: {e}")
                    typer_instance.echo(f"  ‚ö†Ô∏è  Error analyzing {ticker}: {e}")

        # Log token usage summary
        daily_stats = tracker.get_daily_stats()
        if daily_stats:
            typer_instance.echo("\nüí∞ Token Usage Summary:")
            typer_instance.echo(f"  Input tokens: {daily_stats.total_input_tokens:,}")
            typer_instance.echo(f"  Output tokens: {daily_stats.total_output_tokens:,}")
            typer_instance.echo(f"  Cost: ‚Ç¨{daily_stats.total_cost_eur:.2f}")
            typer_instance.echo(f"  Requests: {daily_stats.requests}")

        return signals, None

    except Exception as e:
        logger.error(f"Error in LLM analysis: {e}", exc_info=True)
        typer_instance.echo(f"‚ùå LLM Analysis Error: {e}", err=True)
        return [], None


@app.command()
def analyze(
    market: str = typer.Option(
        None,
        "--market",
        "-m",
        help="Market to analyze: 'global', 'us', 'eu', 'nordic', or comma-separated (e.g., 'us,eu')",
    ),
    group: str = typer.Option(
        None,
        "--group",
        "-g",
        help="Ticker group: sector categories ('us_mega_cap', 'us_tech_software', 'us_ai_ml') or portfolios ('us_portfolio_balanced_conservative', 'us_portfolio_dividend_growth'). Comma-separated for multiple. Use list-categories or list-portfolios to see all options",
    ),
    ticker: str = typer.Option(
        None,
        "--ticker",
        "-t",
        help="Comma-separated list of tickers to analyze (e.g., 'AAPL,MSFT,GOOGL')",
    ),
    limit: int = typer.Option(
        None,
        "--limit",
        "-l",
        help="Maximum number of instruments to analyze per market",
    ),
    config: Path = typer.Option(
        None,
        "--config",
        "-c",
        help="Path to configuration file (default: config/local.yaml or config/default.yaml)",
        exists=True,
    ),
    date: str = typer.Option(
        None,
        "--date",
        "-d",
        help="Analyze as if it were a specific date in the past (YYYY-MM-DD format) for historical analysis",
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Run analysis without executing trades or sending alerts",
    ),
    output_format: str = typer.Option(
        "markdown",
        "--format",
        "-f",
        help="Report format: markdown or json",
    ),
    save_report: bool = typer.Option(
        True,
        "--save-report/--no-save-report",
        help="Save report to disk",
    ),
    use_llm: bool = typer.Option(
        False,
        "--llm",
        help="Use LLM-powered analysis (CrewAI with Claude/GPT) instead of rule-based",
    ),
    debug_llm: bool = typer.Option(
        False,
        "--debug-llm",
        help="Save LLM inputs and outputs to data/llm_debug/ for inspection (only works with --llm)",
    ),
    test: bool = typer.Option(
        False,
        "--test",
        help="Run true test mode with pre-cached fixture data (zero API/LLM cost, fast, reproducible)",
    ),
    fixture: str = typer.Option(
        "test_ticker_minimal",
        "--fixture",
        help="Name of fixture to use in test mode (in data/fixtures/)",
    ),
    force_full_analysis: bool = typer.Option(
        False,
        "--force-full-analysis",
        help="Force LLM analysis on all tickers when market scan finds no anomalies (increases costs)",
    ),
) -> None:
    """Analyze markets and generate investment signals.

    Fetches market data, analyzes instruments, and generates investment
    recommendations with confidence scores.

    Examples:
        # Run quick test (rule-based)
        analyze --test

        # Run quick test (LLM mode)
        analyze --test --llm

        # Analyze with LLM debug mode (saves inputs/outputs)
        analyze --ticker INTU --llm --debug-llm

        # Analyze all available markets
        analyze --market global

        # Analyze US market only
        analyze --market us

        # Analyze multiple markets with limit
        analyze --market us,eu --limit 50

        # Analyze specific tickers
        analyze --ticker AAPL,MSFT,GOOGL

        # Historical date analysis (backtesting)
        analyze --ticker AAPL --date 2024-06-01
        analyze --ticker AAPL --date 2024-06-01 --llm

        # Analyze US groups (categories and portfolios)
        analyze --group us_tech_software
        analyze --group us_ai_ml,us_cybersecurity --limit 30
        analyze --group us_mega_cap
        analyze --group us_portfolio_balanced_conservative
        analyze --group us_portfolio_dividend_growth

        # Combine markets and groups
        analyze --market nordic --group us_tech_software
    """
    start_time = time.time()
    run_log = None
    signals_count = 0
    historical_date = None

    # Parse and validate historical date if provided
    if date:
        try:
            historical_date = datetime.strptime(date, "%Y-%m-%d").date()
            typer.echo(f"üìÖ Historical date analysis mode: {historical_date}")
        except ValueError:
            typer.echo(
                f"‚ùå Error: Invalid date format '{date}'. Use YYYY-MM-DD format (e.g., 2024-06-01)",
                err=True,
            )
            raise typer.Exit(code=1)

    # Handle test mode (true test mode with fixtures)
    if test:
        typer.echo("üß™ Running TRUE TEST MODE (offline, zero cost, reproducible)...")
        typer.echo(f"  Fixture: {fixture}")
        typer.echo("  Data source: Local fixture files (no API calls)")
        if use_llm:
            typer.echo("  LLM: MockLLMClient (zero cost)")
        else:
            typer.echo("  Mode: Rule-based analysis")
        # Don't save report in test mode unless explicitly requested
        if save_report:
            save_report = False
            typer.echo("  Report saving: disabled (test mode)")

    # Validate that either market, group, ticker, or test is provided
    if not market and not group and not ticker and not test:
        typer.echo(
            "‚ùå Error: Either --market, --group, --ticker, or --test must be provided\n"
            "Examples:\n"
            "  analyze --test              # True test mode (offline, zero cost)\n"
            "  analyze --test --llm        # True test with mock LLM\n"
            "  analyze --market global\n"
            "  analyze --market us\n"
            "  analyze --group us_tech_software\n"
            "  analyze --group us_ai_ml,us_cybersecurity --limit 30\n"
            "  analyze --group us_portfolio_balanced_conservative\n"
            "  analyze --market us,eu --limit 50\n"
            "  analyze --ticker AAPL,MSFT,GOOGL",
            err=True,
        )
        raise typer.Exit(code=1)

    if (market or group) and ticker:
        typer.echo("‚ùå Error: Cannot specify --ticker with --market or --group", err=True)
        raise typer.Exit(code=1)

    if test and (market or group or ticker):
        typer.echo(
            "‚ùå Error: Cannot use --test with --market, --group, or --ticker",
            err=True,
        )
        raise typer.Exit(code=1)

    try:
        # Load configuration
        config_obj = load_config(config)

        # Setup logging
        setup_logging(config_obj.logging)

        # Initialize database if enabled
        run_session_id: int | None = None
        session_repo = None
        recommendations_repo = None
        if config_obj.database.enabled:
            init_db(config_obj.database.db_path)
            logger.debug(f"Database initialized at {config_obj.database.db_path}")

            # Initialize repositories for session management
            from src.data.repository import RecommendationsRepository, RunSessionRepository

            session_repo = RunSessionRepository(config_obj.database.db_path)
            recommendations_repo = RecommendationsRepository(config_obj.database.db_path)

        # Check LLM configuration and warn if using fallback mode
        llm_configured = log_llm_status(config_obj.llm.provider)

        # Initialize run log
        data_dir = Path("data")
        run_log = RunLog(data_dir / "runs.jsonl")

        logger.debug(f"Starting NordInvest analysis (dry_run={dry_run})")
        logger.debug(f"Using config: {config}")
        logger.debug(f"Risk tolerance: {config_obj.risk.tolerance}")
        logger.debug(f"Capital: ‚Ç¨{config_obj.capital.starting_capital_eur:,.2f}")

        typer.echo("‚úì Configuration loaded successfully")
        typer.echo(f"  Risk tolerance: {config_obj.risk.tolerance}")
        typer.echo(f"  Capital: ‚Ç¨{config_obj.capital.starting_capital_eur:,.2f}")
        typer.echo(f"  Monthly deposit: ‚Ç¨{config_obj.capital.monthly_deposit_eur:,.2f}")
        typer.echo(f"  Markets: {', '.join(config_obj.markets.included)}")

        if not llm_configured:
            typer.echo(
                "\n" + get_fallback_warning_message(config_obj.llm.provider if use_llm else None)
            )

        if dry_run:
            typer.echo("  [DRY RUN MODE - No trades will be executed]")

        # Initialize pipeline
        typer.echo("\n‚è≥ Initializing analysis pipeline...")
        cache_manager = CacheManager(str(data_dir / "cache"))
        portfolio_manager = PortfolioState(data_dir / "portfolio_state.json")

        # Initialize provider manager for price lookups
        from src.data.provider_manager import ProviderManager

        provider_manager = ProviderManager(
            primary_provider=config_obj.data.primary_provider,
            backup_providers=config_obj.data.backup_providers,
            db_path=config_obj.database.db_path if config_obj.database.enabled else None,
        )

        # Setup test mode if enabled
        if test:
            fixture_path = data_dir / "fixtures" / fixture
            config_obj.test_mode.enabled = True
            config_obj.test_mode.fixture_name = fixture
            config_obj.test_mode.fixture_path = str(fixture_path)
            config_obj.test_mode.use_mock_llm = use_llm
            logger.debug(f"Test mode enabled with fixture: {fixture}")

        pipeline = AnalysisPipeline(
            config_obj,
            cache_manager,
            portfolio_manager,
            llm_provider=config_obj.llm.provider,
            test_mode_config=config_obj.test_mode if test else None,
            db_path=config_obj.database.db_path if config_obj.database.enabled else None,
            run_session_id=run_session_id,
            provider_manager=provider_manager,
        )

        # Determine which tickers to analyze
        if test:
            # In test mode, load ticker from fixture metadata
            from src.data.fixture import FixtureDataProvider

            fixture_path = data_dir / "fixtures" / fixture
            if not fixture_path.exists():
                typer.echo(f"‚ùå Error: Fixture not found: {fixture_path}", err=True)
                raise typer.Exit(code=1)

            fixture_provider = FixtureDataProvider(fixture_path)
            metadata = fixture_provider.get_fixture_metadata()
            test_ticker = metadata.get("ticker", "AAPL")
            ticker_list = [test_ticker]
            typer.echo("\nüìä Running analysis on test fixture...")
            typer.echo(f"  Ticker: {test_ticker}")
        elif ticker:
            # Parse comma-separated tickers
            ticker_list = [t.strip().upper() for t in ticker.split(",")]
            typer.echo(f"\nüìä Running analysis on {len(ticker_list)} specified instruments...")
            typer.echo(f"  Tickers: {', '.join(ticker_list)}")
        elif group:
            # Parse group specification
            groups = [g.strip().lower() for g in group.split(",")]
            typer.echo(f"\nüìä Running analysis for group(s): {', '.join(groups).upper()}...")

            # Validate groups
            available_groups = get_us_categories()
            invalid_groups = [g for g in groups if g not in available_groups]
            if invalid_groups:
                typer.echo(
                    f"‚ùå Error: Invalid group(s): {', '.join(invalid_groups)}",
                    err=True,
                )
                typer.echo("Available groups:", err=True)
                for group_name, count in sorted(available_groups.items()):
                    typer.echo(f"  {group_name}: {count} tickers", err=True)
                sys.exit(1)

            # Get tickers from groups, optionally combined with markets
            if market:
                markets = (
                    ["global"]
                    if market.lower() == "global"
                    else [m.strip().lower() for m in market.split(",")]
                )
                if market.lower() == "global":
                    markets = ["nordic", "eu"]
                ticker_list = get_tickers_for_analysis(
                    markets=markets, categories=groups, limit_per_category=limit
                )
                typer.echo(f"  Markets: {', '.join(markets).upper()}")
            else:
                ticker_list = get_tickers_for_analysis(categories=groups, limit_per_category=limit)

            if limit:
                typer.echo(f"  Limit: {limit} instruments per group")
            typer.echo(f"  Total instruments to analyze: {len(ticker_list)}")
        else:
            # Parse market specification
            if market.lower() == "global":
                markets = ["nordic", "eu", "us"]
                typer.echo("\nüåç Running GLOBAL market analysis...")
            else:
                markets = [m.strip().lower() for m in market.split(",")]
                typer.echo(f"\nüìä Running analysis for market(s): {', '.join(markets).upper()}...")

            # Validate markets
            valid_markets = ["nordic", "eu", "us"]
            invalid_markets = [m for m in markets if m not in valid_markets]
            if invalid_markets:
                typer.echo(
                    f"‚ùå Error: Invalid market(s): {', '.join(invalid_markets)}\n"
                    f"Valid markets: {', '.join(valid_markets)}, global",
                    err=True,
                )
                raise typer.Exit(code=1)

            ticker_list = get_tickers_for_markets(markets, limit=limit)

            if limit:
                typer.echo(f"  Limit: {limit} instruments per market")
            typer.echo(f"  Total instruments to analyze: {len(ticker_list)}")

        # Prepare analysis context metadata
        analyzed_group = None
        analyzed_market = None
        analyzed_tickers_specified = []
        tickers_with_anomalies = []
        force_full_analysis_used = False

        if ticker:
            analyzed_tickers_specified = [t.strip().upper() for t in ticker.split(",")]
        elif group:
            analyzed_group = group
        else:
            analyzed_market = market

        # Setup historical data fetcher if analyzing historical data
        historical_context_data = {}
        if historical_date:
            from src.data.historical import HistoricalDataFetcher
            from src.data.provider_manager import ProviderManager

            typer.echo("\nüìÖ Preparing historical data fetcher...")
            # Get the primary data provider
            provider_manager = ProviderManager()
            primary_provider = provider_manager.primary_provider
            # Pass cache_manager to enable historical cache retrieval
            historical_fetcher = HistoricalDataFetcher(
                primary_provider, cache_manager=cache_manager
            )

            # Fetch historical context for each ticker
            typer.echo(f"  Fetching historical data as of {historical_date}...")
            for tick in ticker_list:
                try:
                    context = historical_fetcher.fetch_as_of_date(
                        tick, historical_date, lookback_days=365
                    )
                    historical_context_data[tick] = context
                except Exception as e:
                    typer.echo(f"  ‚ö†Ô∏è  Error fetching historical data for {tick}: {e}")
                    historical_context_data[tick] = None

            if historical_context_data:
                typer.echo(
                    f"  ‚úì Historical data fetched for {len(historical_context_data)} instruments"
                )

        # Create run session if database is enabled
        if session_repo:
            run_session_id = session_repo.create_session(
                analysis_mode="llm" if use_llm else "rule_based",
                analyzed_category=analyzed_group,
                analyzed_market=analyzed_market,
                analyzed_tickers_specified=analyzed_tickers_specified
                if analyzed_tickers_specified
                else None,
                initial_tickers_count=len(ticker_list),
                anomalies_count=0,  # Will be updated after market scan in LLM mode
                force_full_analysis=force_full_analysis,
            )
            # Update pipeline with session ID
            pipeline.run_session_id = run_session_id
            logger.debug(f"Created run session: {run_session_id}")

        # Run analysis (LLM or rule-based)
        if use_llm:
            typer.echo("\nü§ñ Using two-stage LLM-powered analysis")
            typer.echo("   Stage 1: Rule-based market scan for anomalies")
            typer.echo("   Stage 2: Deep LLM analysis on flagged instruments")

            # Stage 1: Market scan to identify anomalies
            try:
                filtered_ticker_list = _scan_market_for_anomalies(
                    ticker_list, pipeline, typer, force_full_analysis, historical_date
                )
                # If force_full_analysis is False and we got here, anomalies were found
                # If force_full_analysis is True and no filtering happened, flag was used
                if force_full_analysis and len(filtered_ticker_list) == len(ticker_list):
                    # --force-full-analysis was used and no anomalies were found
                    force_full_analysis_used = True
                else:
                    # Anomalies were found (whether filtered or not)
                    tickers_with_anomalies = filtered_ticker_list
            except RuntimeError as e:
                # Display error cleanly without traceback
                typer.echo(f"\n‚ùå Error: {str(e)}", err=True)
                sys.exit(1)

            # Show filtering results
            if len(filtered_ticker_list) < len(ticker_list):
                reduction_pct = 100 * (1 - len(filtered_ticker_list) / len(ticker_list))
                typer.echo(
                    f"\n‚úÖ Filtering complete: {len(filtered_ticker_list)}/{len(ticker_list)} "
                    f"instruments selected ({reduction_pct:.0f}% reduction)"
                )
                typer.echo(f"   Estimated cost savings: ~{reduction_pct:.0f}% lower API usage")

            # Stage 2: LLM analysis on filtered list
            typer.echo()
            signals, portfolio_manager = _run_llm_analysis(
                filtered_ticker_list,
                config_obj,
                typer,
                debug_llm,
                is_filtered=True,
                cache_manager=cache_manager,
                provider_manager=provider_manager,
                historical_date=historical_date,
                run_session_id=run_session_id,
                recommendations_repo=recommendations_repo,
            )
            analysis_mode = "llm"
        else:
            typer.echo(
                "\nüìä Using rule-based analysis (technical indicators & fundamental metrics)"
            )
            # Pass historical context if available
            analysis_context = {}
            if historical_context_data:
                analysis_context["historical_contexts"] = historical_context_data
                analysis_context["analysis_date"] = historical_date
            signals, portfolio_manager = pipeline.run_analysis(ticker_list, analysis_context)
            analysis_mode = "rule_based"
        signals_count = len(signals)

        # Complete run session if database is enabled
        if session_repo and run_session_id:
            # Calculate failed count (initial tickers - generated signals)
            initial_count = len(ticker_list)
            failed_count = initial_count - signals_count

            # Determine status
            if signals_count == initial_count:
                status = "completed"
            elif signals_count > 0:
                status = "partial"
            else:
                status = "failed"

            session_repo.complete_session(
                session_id=run_session_id,
                signals_generated=signals_count,
                signals_failed=failed_count,
                status=status,
            )
            logger.debug(f"Completed run session: {run_session_id} (status: {status})")

        if signals:
            typer.echo(f"‚úì Analysis complete: {signals_count} signals generated")

            # Generate report
            typer.echo("\nüìã Generating report...")
            # Use historical date for report if provided
            report_date = historical_date.strftime("%Y-%m-%d") if historical_date else None
            report = pipeline.generate_daily_report(
                signals,
                generate_allocation=True,
                report_date=report_date,
                analysis_mode=analysis_mode,
                analyzed_category=analyzed_group,
                analyzed_market=analyzed_market,
                analyzed_tickers_specified=analyzed_tickers_specified,
                initial_tickers=ticker_list,
                tickers_with_anomalies=tickers_with_anomalies,
                force_full_analysis_used=force_full_analysis_used,
            )

            # Display summary
            typer.echo("\nüìà Report Summary:")
            typer.echo(f"  Strong signals: {report.strong_signals_count}")
            typer.echo(f"  Moderate signals: {report.moderate_signals_count}")
            typer.echo(f"  Total analyzed: {report.total_signals_generated}")

            if report.allocation_suggestion:
                typer.echo(
                    f"  Diversification score: {report.allocation_suggestion.diversification_score}%"
                )
                typer.echo(
                    f"  Recommended allocation: ‚Ç¨{report.allocation_suggestion.total_allocated:,.0f}"
                )

            # Save report if requested
            if save_report:
                reports_dir = data_dir / "reports"
                reports_dir.mkdir(parents=True, exist_ok=True)
                timestamp = datetime.now().strftime("%H-%M-%S")

                if output_format == "markdown":
                    report_path = reports_dir / f"report_{report.report_date}_{timestamp}.md"
                    report_content = pipeline.report_generator.to_markdown(report)
                    with open(report_path, "w") as f:
                        f.write(report_content)
                    typer.echo(f"  Report saved: {report_path}")
                else:
                    report_path = reports_dir / f"report_{report.report_date}_{timestamp}.json"
                    with open(report_path, "w") as f:
                        json.dump(pipeline.report_generator.to_json(report), f, indent=2)
                    typer.echo(f"  Report saved: {report_path}")
        else:
            typer.echo("‚ö†Ô∏è  No signals generated from analysis")

        duration = time.time() - start_time
        logger.debug(f"Analysis run completed successfully in {duration:.2f}s")
        typer.echo(f"\n‚úì Analysis completed in {duration:.2f}s")

        # Log the run
        if run_log:
            run_log.log_run(
                success=True,
                duration_seconds=duration,
                signal_count=signals_count,
            )

    except FileNotFoundError as e:
        logger.error(f"Configuration error: {e}")
        typer.echo(f"‚ùå Error: {e}", err=True)
        if run_log:
            duration = time.time() - start_time
            run_log.log_run(
                success=False,
                duration_seconds=duration,
                signal_count=signals_count,
                error_message=str(e),
            )
        raise typer.Exit(code=1)
    except ValueError as e:
        logger.error(f"Configuration validation error: {e}")
        typer.echo(f"‚ùå Configuration error: {e}", err=True)
        if run_log:
            duration = time.time() - start_time
            run_log.log_run(
                success=False,
                duration_seconds=duration,
                signal_count=signals_count,
                error_message=str(e),
            )
        raise typer.Exit(code=1)
    except Exception as e:
        logger.exception(f"Unexpected error during analysis run: {e}")
        typer.echo(f"‚ùå Error: {e}", err=True)
        if run_log:
            duration = time.time() - start_time
            run_log.log_run(
                success=False,
                duration_seconds=duration,
                signal_count=signals_count,
                error_message=str(e),
            )
        raise typer.Exit(code=1)


@app.command()
def report(
    session_id: int | None = typer.Option(
        None, "--session-id", help="Generate report from run session ID (integer)"
    ),
    date: str | None = typer.Option(
        None, "--date", help="Generate report for specific date (YYYY-MM-DD)"
    ),
    output_format: str = typer.Option(
        "markdown", "--format", help="Output format: markdown or json"
    ),
    save_report: bool = typer.Option(
        True, "--save/--no-save", help="Save report to file (default: save)"
    ),
    config: str = typer.Option(
        "config/default.yaml",
        "--config",
        "-c",
        help="Path to configuration file",
    ),
) -> None:
    """Generate report from stored database results.

    Load investment signals from the database and regenerate reports.
    You can specify either a run session ID or a date.

    Examples:
        # Generate report from a specific session
        report --session-id 02a27c22-a123-4378-8654-95c592a66e2f

        # Generate report for all signals from a specific date
        report --date 2025-12-04

        # Generate JSON report instead of markdown
        report --session-id abc123 --format json
    """
    try:
        # Validate inputs
        if not session_id and not date:
            typer.echo("‚ùå Error: Must specify either --session-id or --date", err=True)
            typer.echo("Examples:", err=True)
            typer.echo("  report --session-id 02a27c22-a123-4378-8654-95c592a66e2f", err=True)
            typer.echo("  report --date 2025-12-04", err=True)
            raise typer.Exit(code=1)

        if session_id and date:
            typer.echo(
                "‚ùå Error: Cannot specify both --session-id and --date. Choose one.", err=True
            )
            raise typer.Exit(code=1)

        # Validate date format if provided
        if date:
            try:
                datetime.strptime(date, "%Y-%m-%d")
            except ValueError:
                typer.echo(f"‚ùå Error: Invalid date format '{date}'. Use YYYY-MM-DD", err=True)
                raise typer.Exit(code=1)

        # Load configuration
        config_obj = load_config(config)

        # Setup logging
        setup_logging(config_obj.logging)

        # Check if database is enabled
        if not config_obj.database.enabled:
            typer.echo(
                "‚ùå Error: Database is not enabled in configuration.\n"
                "   Enable database in config file to use historical reports.",
                err=True,
            )
            raise typer.Exit(code=1)

        # Initialize database
        init_db(config_obj.database.db_path)
        logger.debug(f"Database initialized at {config_obj.database.db_path}")

        typer.echo("üìä Generating report from database...")
        if session_id:
            typer.echo(f"  Session ID: {session_id}")
        else:
            typer.echo(f"  Date: {date}")

        # Initialize components
        data_dir = Path("data")
        cache_manager = CacheManager(str(data_dir / "cache"))
        portfolio_manager = PortfolioState(data_dir / "portfolio_state.json")

        # Initialize provider manager for price lookups
        from src.data.provider_manager import ProviderManager

        provider_manager = ProviderManager(
            primary_provider=config_obj.data.primary_provider,
            backup_providers=config_obj.data.backup_providers,
            db_path=config_obj.database.db_path if config_obj.database.enabled else None,
        )

        pipeline = AnalysisPipeline(
            config_obj,
            cache_manager,
            portfolio_manager,
            llm_provider=config_obj.llm.provider,
            test_mode_config=None,
            db_path=config_obj.database.db_path,
            run_session_id=session_id,  # Pass session_id if provided
            provider_manager=provider_manager,
        )

        # Generate report from database
        report_obj = pipeline.generate_daily_report(
            signals=None,  # Load from database
            generate_allocation=True,
            report_date=date,
            run_session_id=session_id,
        )

        # Display summary
        typer.echo("\nüìà Report Summary:")
        typer.echo(f"  Report date: {report_obj.report_date}")
        typer.echo(f"  Strong signals: {report_obj.strong_signals_count}")
        typer.echo(f"  Moderate signals: {report_obj.moderate_signals_count}")
        typer.echo(f"  Total analyzed: {report_obj.total_signals_generated}")

        if report_obj.allocation_suggestion:
            typer.echo(
                f"  Diversification score: {report_obj.allocation_suggestion.diversification_score}%"
            )
            typer.echo(
                f"  Recommended allocation: ‚Ç¨{report_obj.allocation_suggestion.total_allocated:,.0f}"
            )

        # Save report if requested
        if save_report:
            reports_dir = data_dir / "reports"
            reports_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%H-%M-%S")

            if output_format == "markdown":
                report_path = reports_dir / f"report_{report_obj.report_date}_{timestamp}.md"
                report_content = pipeline.report_generator.to_markdown(report_obj)
                with open(report_path, "w") as f:
                    f.write(report_content)
                typer.echo(f"\n‚úì Report saved: {report_path}")
            else:
                report_path = reports_dir / f"report_{report_obj.report_date}_{timestamp}.json"
                with open(report_path, "w") as f:
                    json.dump(pipeline.report_generator.to_json(report_obj), f, indent=2)
                typer.echo(f"\n‚úì Report saved: {report_path}")
        else:
            typer.echo("\n‚úì Report generated (not saved)")

    except typer.Exit:
        raise
    except Exception as e:
        logger.error(f"Error generating report: {e}", exc_info=True)
        typer.echo(f"\n‚ùå Error generating report: {e}", err=True)
        raise typer.Exit(code=1)


@app.command()
def list_categories() -> None:
    """List all available US ticker categories.

    Shows all category names with the number of tickers in each.
    Use these category names with the `analyze --group` option.
    """
    categories = get_us_categories()

    typer.echo("\nüá∫üá∏ Available US Ticker Categories:\n")

    # Group by type for better readability
    groups = {
        "Market Cap": ["us_mega_cap", "us_large_cap", "us_mid_cap", "us_small_cap"],
        "Technology": [
            "us_tech",
            "us_tech_software",
            "us_tech_semiconductors",
            "us_tech_hardware",
            "us_tech_internet",
        ],
        "Healthcare": ["us_healthcare", "us_healthcare_pharma", "us_healthcare_devices"],
        "Financials": [
            "us_financials",
            "us_financials_banks",
            "us_financials_fintech",
            "us_financials_asset_mgmt",
        ],
        "Consumer": [
            "us_consumer",
            "us_consumer_retail",
            "us_consumer_food_bev",
            "us_consumer_restaurants",
        ],
        "Other Sectors": [
            "us_industrials",
            "us_energy",
            "us_clean_energy",
            "us_utilities",
            "us_real_estate",
            "us_materials",
            "us_communication",
            "us_transportation",
        ],
        "Themes": [
            "us_ai_ml",
            "us_cybersecurity",
            "us_cloud_computing",
            "us_space_defense",
            "us_ev_autonomous",
            "us_biotech_genomics",
            "us_quantum_computing",
        ],
        "ETFs": [
            "us_etfs",
            "us_etfs_broad_market",
            "us_etfs_sector",
            "us_etfs_fixed_income",
            "us_etfs_international",
            "us_etfs_thematic",
            "us_etfs_dividend",
        ],
    }

    for group_name, cat_list in groups.items():
        typer.echo(f"üìå {group_name}:")
        for cat in cat_list:
            if cat in categories:
                count = categories[cat]
                typer.echo(f"  ‚Ä¢ {cat}: {count} tickers")
        typer.echo()

    # Usage examples
    typer.echo("üí° Usage Examples:")
    typer.echo("  analyze --group us_tech_software")
    typer.echo("  analyze --group us_ai_ml,us_cybersecurity --limit 30")
    typer.echo("  analyze --market nordic --group us_tech_software")
    typer.echo()


@app.command()
def list_portfolios() -> None:
    """List all available diversified portfolio categories.

    Shows all pre-built portfolio categories with the number of tickers in each.
    Use these portfolio names with the `analyze --group` option.
    """
    categories = get_us_categories()

    # Filter for portfolio categories only
    portfolio_categories = {k: v for k, v in categories.items() if k.startswith("us_portfolio_")}

    typer.echo("\nüíº Available Diversified Portfolio Categories:\n")

    # Group by portfolio type for better readability
    groups = {
        "Balanced Portfolios": [
            "us_portfolio_balanced_conservative",
            "us_portfolio_balanced_moderate",
            "us_portfolio_balanced_aggressive",
        ],
        "Income Portfolios": [
            "us_portfolio_dividend_aristocrats",
            "us_portfolio_high_yield",
            "us_portfolio_dividend_growth",
        ],
        "Growth Portfolios": [
            "us_portfolio_tech_growth",
            "us_portfolio_next_gen_tech",
            "us_portfolio_disruptive",
        ],
        "Value Portfolios": [
            "us_portfolio_deep_value",
            "us_portfolio_garp",
            "us_portfolio_quality_value",
        ],
        "Economic Cycle": [
            "us_portfolio_expansion",
            "us_portfolio_contraction",
            "us_portfolio_inflation_hedge",
        ],
        "Thematic": [
            "us_portfolio_aging_population",
            "us_portfolio_millennial",
            "us_portfolio_infrastructure",
            "us_portfolio_reshoring",
            "us_portfolio_water",
        ],
        "International": [
            "us_portfolio_global_leaders",
            "us_portfolio_emerging_markets",
        ],
        "Risk Parity": [
            "us_portfolio_all_weather",
            "us_portfolio_permanent",
            "us_portfolio_golden_butterfly",
        ],
    }

    for group_name, portfolio_list in groups.items():
        typer.echo(f"üìå {group_name}:")
        for portfolio in portfolio_list:
            if portfolio in portfolio_categories:
                count = portfolio_categories[portfolio]
                typer.echo(f"  ‚Ä¢ {portfolio}: {count} tickers")
        typer.echo()

    # Summary
    total_portfolios = len(portfolio_categories)
    total_tickers = sum(portfolio_categories.values())
    typer.echo("üìä Summary:")
    typer.echo(f"  Total portfolios: {total_portfolios}")
    typer.echo(f"  Total tickers across all portfolios: {total_tickers}")
    typer.echo()

    # Usage examples
    typer.echo("üí° Usage Examples:")
    typer.echo("  analyze --group us_portfolio_balanced_conservative")
    typer.echo("  analyze --group us_portfolio_dividend_growth")
    typer.echo("  analyze --group us_portfolio_tech_growth --llm")
    typer.echo("  analyze --group us_portfolio_all_weather")
    typer.echo()


@app.command()
def config_init(
    output: Path = typer.Option(
        Path("config/local.yaml"),
        "--output",
        "-o",
        help="Output path for local configuration file",
    ),
) -> None:
    """Initialize local configuration from template.

    Creates a local.yaml file based on the default.yaml template
    that you can customize for your preferences.
    """
    try:
        project_root = Path(__file__).parent.parent
        default_config = project_root / "config" / "default.yaml"

        if not default_config.exists():
            typer.echo(f"‚ùå Default config not found: {default_config}", err=True)
            raise typer.Exit(code=1)

        # Read default config
        with open(default_config, "r") as f:
            default_content = f.read()

        # Create output directory
        output.parent.mkdir(parents=True, exist_ok=True)

        # Write local config
        with open(output, "w") as f:
            f.write(default_content)

        logger.debug(f"Local configuration initialized: {output}")
        typer.echo(f"‚úì Configuration template created: {output}")
        typer.echo("  Please edit this file with your preferences")

    except Exception as e:
        logger.exception(f"Error initializing configuration: {e}")
        typer.echo(f"‚ùå Error: {e}", err=True)
        raise typer.Exit(code=1)


@app.command()
def validate_config(
    config: Path = typer.Option(
        None,
        "--config",
        "-c",
        help="Path to configuration file",
        exists=True,
    ),
) -> None:
    """Validate configuration file.

    Loads and validates the configuration without running analysis,
    useful for checking configuration before deployment.
    """
    try:
        config_obj = load_config(config)

        typer.echo("‚úì Configuration is valid")
        typer.echo(f"  Risk tolerance: {config_obj.risk.tolerance}")
        typer.echo(f"  Capital: ‚Ç¨{config_obj.capital.starting_capital_eur:,.2f}")
        typer.echo(f"  Markets: {', '.join(config_obj.markets.included)}")
        typer.echo(f"  Instruments: {', '.join(config_obj.markets.included_instruments)}")
        typer.echo(f"  Buy threshold: {config_obj.analysis.buy_threshold}")
        typer.echo(f"  Cost limit: ‚Ç¨{config_obj.deployment.cost_limit_eur_per_month:.2f}/month")

    except FileNotFoundError as e:
        logger.error(f"Configuration file not found: {e}")
        typer.echo(f"‚ùå Error: {e}", err=True)
        raise typer.Exit(code=1)
    except ValueError as e:
        logger.error(f"Configuration validation failed: {e}")
        typer.echo(f"‚ùå Configuration error: {e}", err=True)
        raise typer.Exit(code=1)
    except Exception as e:
        logger.exception(f"Unexpected error validating configuration: {e}")
        typer.echo(f"‚ùå Error: {e}", err=True)
        raise typer.Exit(code=1)


@app.command()
def track_performance(
    max_age_days: int = typer.Option(
        180,
        "--max-age",
        "-m",
        help="Maximum age of recommendations to track (in days)",
    ),
    signal_types: str = typer.Option(
        "buy,strong_buy",
        "--signals",
        "-s",
        help="Comma-separated list of signal types to track",
    ),
    benchmark: str = typer.Option(
        "SPY",
        "--benchmark",
        "-b",
        help="Benchmark ticker symbol for comparison",
    ),
    config: Path = typer.Option(
        None,
        "--config",
        "-c",
        help="Path to configuration file",
        exists=True,
    ),
) -> None:
    """Track performance of active recommendations.

    Fetches current prices for all active recommendations and stores
    them for performance analysis. This should be run daily to maintain
    accurate performance tracking.

    Examples:
        track-performance
        track-performance --max-age 90
        track-performance --signals buy,strong_buy,hold
        track-performance --benchmark QQQ
    """
    try:
        # Load configuration
        config_obj = load_config(config)

        # Setup logging
        setup_logging(config_obj.logging)
        logger.info("Starting performance tracking")

        db_path = Path(
            config_obj.database.db_path if config_obj.database.enabled else "data/nordinvest.db"
        )

        # Initialize repositories
        from src.data.provider_manager import ProviderManager
        from src.data.repository import PerformanceRepository

        perf_repo = PerformanceRepository(db_path)
        provider_manager = ProviderManager(
            primary_provider=config_obj.data.primary_provider,
            backup_providers=config_obj.data.backup_providers,
            db_path=db_path,
        )

        # Parse signal types
        signal_list = [s.strip() for s in signal_types.split(",")]

        # Get active recommendations
        typer.echo("\nüìä Fetching active recommendations...")
        recommendations = perf_repo.get_active_recommendations(
            max_age_days=max_age_days, signal_types=signal_list
        )

        if not recommendations:
            typer.echo("  No active recommendations found to track")
            return

        typer.echo(f"  Found {len(recommendations)} active recommendations")

        # Track prices
        tracked_count = 0
        failed_count = 0
        today = date.today()

        typer.echo(f"\n‚è≥ Tracking prices (benchmark: {benchmark})...")

        for rec in recommendations:
            try:
                # Get ticker symbol
                ticker_symbol = rec.ticker_obj.symbol if rec.ticker_obj else None
                if not ticker_symbol:
                    logger.warning(f"Skipping recommendation {rec.id}: no ticker symbol")
                    failed_count += 1
                    continue

                # Fetch current price
                price_obj = provider_manager.get_latest_price(ticker_symbol)
                if not price_obj:
                    logger.warning(f"No price data for {ticker_symbol}")
                    failed_count += 1
                    continue

                current_price = price_obj.close_price

                # Fetch benchmark price
                benchmark_price = None
                benchmark_obj = provider_manager.get_latest_price(benchmark)
                if benchmark_obj:
                    benchmark_price = benchmark_obj.close_price

                # Track the price
                success = perf_repo.track_price(
                    recommendation_id=rec.id,
                    tracking_date=today,
                    price=current_price,
                    benchmark_price=benchmark_price,
                    benchmark_ticker=benchmark,
                )

                if success:
                    tracked_count += 1
                    logger.debug(f"Tracked {ticker_symbol}: ${current_price:.2f}")
                else:
                    failed_count += 1

            except Exception as e:
                logger.error(f"Error tracking recommendation {rec.id}: {e}")
                failed_count += 1

        # Summary
        typer.echo("\n‚úÖ Performance tracking complete:")
        typer.echo(f"  Tracked: {tracked_count} recommendations")
        if failed_count > 0:
            typer.echo(f"  Failed: {failed_count} recommendations")

        logger.info(
            f"Performance tracking complete: {tracked_count} tracked, {failed_count} failed"
        )

    except Exception as e:
        logger.error(f"Error in performance tracking: {e}", exc_info=True)
        typer.echo(f"\n‚ùå Error: {e}", err=True)
        raise typer.Exit(code=1)


@app.command()
def performance_report(
    period: int = typer.Option(
        30,
        "--period",
        "-p",
        help="Tracking period in days (7, 30, 90, 180)",
    ),
    ticker: str = typer.Option(
        None,
        "--ticker",
        "-t",
        help="Filter by ticker symbol",
    ),
    signal_type: str = typer.Option(
        None,
        "--signal",
        "-s",
        help="Filter by signal type (buy, strong_buy, etc.)",
    ),
    analysis_mode: str = typer.Option(
        None,
        "--mode",
        "-m",
        help="Filter by analysis mode (rule_based, llm)",
    ),
    update_summary: bool = typer.Option(
        True,
        "--update/--no-update",
        help="Update performance summary before generating report",
    ),
    format: str = typer.Option(
        "text",
        "--format",
        "-f",
        help="Output format: text or json",
    ),
    config: Path = typer.Option(
        None,
        "--config",
        "-c",
        help="Path to configuration file",
        exists=True,
    ),
) -> None:
    """Generate performance report for recommendations.

    Shows aggregated performance metrics including returns, win rate,
    alpha vs benchmark, and confidence calibration.

    Examples:
        performance-report
        performance-report --period 90
        performance-report --ticker AAPL
        performance-report --signal buy --mode llm
        performance-report --format json
    """
    try:
        # Load configuration
        config_obj = load_config(config)

        # Setup logging
        setup_logging(config_obj.logging)
        logger.info("Generating performance report")

        db_path = Path(
            config_obj.database.db_path if config_obj.database.enabled else "data/nordinvest.db"
        )

        # Initialize repository
        from src.data.repository import PerformanceRepository

        perf_repo = PerformanceRepository(db_path)

        # Update performance summary if requested
        if update_summary:
            typer.echo("\n‚è≥ Updating performance summary...")
            success = perf_repo.update_performance_summary(
                ticker_id=None,  # Will be resolved from ticker symbol
                signal_type=signal_type,
                analysis_mode=analysis_mode,
                period_days=period,
            )
            if not success:
                typer.echo("  ‚ö†Ô∏è  Warning: Failed to update performance summary")

        # Generate report
        typer.echo(f"\nüìä Generating performance report (period: {period} days)...")
        report = perf_repo.get_performance_report(
            ticker_symbol=ticker,
            signal_type=signal_type,
            analysis_mode=analysis_mode,
            period_days=period,
        )

        if not report or "message" in report:
            typer.echo(f"\n  {report.get('message', 'No performance data available')}")
            return

        # Display report
        if format == "json":
            import json

            typer.echo("\n" + json.dumps(report, indent=2))
        else:
            # Text format
            typer.echo("\n" + "=" * 60)
            typer.echo("üìà PERFORMANCE REPORT")
            typer.echo("=" * 60)

            typer.echo(f"\nüìÖ Period: {period} days")
            if ticker:
                typer.echo(f"üéØ Ticker: {ticker}")
            if signal_type:
                typer.echo(f"üìä Signal Type: {signal_type}")
            if analysis_mode:
                typer.echo(f"ü§ñ Analysis Mode: {analysis_mode}")

            typer.echo(f"\nüì¶ Total Recommendations: {report.get('total_recommendations', 0)}")

            typer.echo("\nüí∞ Returns:")
            avg_return = report.get("avg_return")
            if avg_return is not None:
                typer.echo(f"  Average Return: {avg_return:+.2f}%")
            median_return = report.get("median_return")
            if median_return is not None:
                typer.echo(f"  Median Return: {median_return:+.2f}%")

            win_rate = report.get("win_rate")
            if win_rate is not None:
                typer.echo(f"\nüéØ Win Rate: {win_rate:.1f}%")

            avg_alpha = report.get("avg_alpha")
            if avg_alpha is not None:
                typer.echo(f"\nüìä Alpha (vs SPY): {avg_alpha:+.2f}%")

            sharpe_ratio = report.get("sharpe_ratio")
            if sharpe_ratio is not None:
                typer.echo(f"\n‚öñÔ∏è  Sharpe Ratio: {sharpe_ratio:.2f}")

            max_drawdown = report.get("max_drawdown")
            if max_drawdown is not None:
                typer.echo(f"üìâ Max Drawdown: {max_drawdown:.2f}%")

            avg_confidence = report.get("avg_confidence")
            calibration_error = report.get("calibration_error")
            if avg_confidence is not None and calibration_error is not None:
                typer.echo("\nüé≤ Confidence Calibration:")
                typer.echo(f"  Average Confidence: {avg_confidence:.1f}%")
                typer.echo(f"  Calibration Error: {calibration_error:.1f}%")

            typer.echo("\n" + "=" * 60)

        logger.info("Performance report generated successfully")

    except Exception as e:
        logger.error(f"Error generating performance report: {e}", exc_info=True)
        typer.echo(f"\n‚ùå Error: {e}", err=True)
        raise typer.Exit(code=1)


@app.callback()
def version_callback(
    version: bool = typer.Option(None, "--version", "-v", help="Show version and exit"),
) -> None:
    """Show version information."""
    if version:
        typer.echo("NordInvest v0.1.0")
        raise typer.Exit()


def main() -> None:
    """Main entry point for CLI."""
    app()


if __name__ == "__main__":
    main()
